{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4353ff5-aa3e-48d6-a9e0-3a4d44244d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm\n",
    "import seaborn as sns\n",
    "import dabest\n",
    "import NLCLIMB\n",
    "import NLMATH\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "date = datetime.today().strftime('%Y%m%d')\n",
    "from statistics import mean\n",
    "from textwrap import wrap\n",
    "\n",
    "import dabest_2023\n",
    "import dabest\n",
    "import dabest_jck\n",
    "import plotly.express as px \n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objects import Layout\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "#NOTE: SUPPRESSES WARNINGS!\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5dfa46-42fe-4f01-b99e-d0273f992f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial file processing\n",
    "workcomp = \"C:\\\\Users\\\\User\"\n",
    "computer2 = \"C:\\\\Users\\\\lnico\"\n",
    "homecomp = \"D:\"\n",
    "filedir = \"\\\\ACC Lab Dropbox\\\\ACC Lab\\\\Nicole Lee\\\\Data Compilation\\\\Falling_New\\\\\"\n",
    "openPath = homecomp + filedir\n",
    "files = os.listdir(openPath)\n",
    "\n",
    "#identifying genotypes\n",
    "responder = \"Chrimson2\"\n",
    "respondercsv = responder + \".csv\"\n",
    "wt = \"w1118\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba357c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "\n",
    "\n",
    "for file_no in os.listdir(openPath): \n",
    "    if respondercsv in file_no and \"w1118\" not in file_no :   #wt > acr files\n",
    "        f = os.path.join(openPath, file_no)\n",
    "        dfe=pd.read_csv(f)\n",
    "        exptdf = dfe.drop(dfe.columns[[0]],axis = 1)\n",
    "        driver = file_no.split(\" \")[0]\n",
    "        lst.append(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ca860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflists = ['df_bspeed', 'df_speed', 'df_time', 'df_fall','df_height', 'df_displacement', 'df_meanpause', 'df_pause','df_meanbout', 'df_bout','df_boutpos', 'df_pausepos','df_maxvelocity','df_straightindex', 'df_displacementbetweenpause']\n",
    "    \n",
    "dflists2 = [s.replace('df_', 'dfreg_') for s in dflists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3b439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_deltav(df_sp, metric):\n",
    "    \n",
    "    df6 = df_sp[(df_sp['ExperimentState'] != \"Recovery\") ]\n",
    "    name = []\n",
    "    if any(df6[metric].isnull()):\n",
    "        name = df6[df6[metric].isnull()]['index'].tolist()\n",
    "    dfsp_db = df6[~df6['index'].isin(name)]\n",
    "           \n",
    "    dfsp_db2 = dabest.load(data = dfsp_db, x = [\"ExperimentState\", \"Type\"], y = metric,  delta2 = True, experiment = \"Type\",\n",
    "                            experiment_label = ['WT', 'Expt'], x1_level = [\"Dark\", \"Full\"], paired = \"baseline\", id_col=\"index\" ) #if delta2 = dabest; deltaG = dabest_jck\n",
    "    plot_data = dfsp_db2._plot_data\n",
    "    idx = dfsp_db2.idx\n",
    "    xvar = dfsp_db2._xvar\n",
    "    yvar = dfsp_db2._yvar\n",
    "    is_paired = dfsp_db2.is_paired\n",
    "    id_col = dfsp_db2.id_col\n",
    "\n",
    "    delta_plot_data_temp = plot_data.copy()\n",
    "    delta_id_col = id_col\n",
    "    delta_plot_data = delta_plot_data_temp[[xvar, yvar, delta_id_col]]\n",
    "\n",
    "    final_deltas = pd.DataFrame()\n",
    "    for i in idx:\n",
    "        for j in i:\n",
    "            if i.index(j) != 0:\n",
    "                temp_df_exp = delta_plot_data[\n",
    "                    delta_plot_data[xvar].str.contains(j)\n",
    "                ].reset_index(drop=True)\n",
    "                if is_paired == \"baseline\":\n",
    "                    temp_df_cont = delta_plot_data[\n",
    "                        delta_plot_data[xvar].str.contains(i[0])\n",
    "                    ].reset_index(drop=True)\n",
    "                elif is_paired == \"sequential\":\n",
    "                    temp_df_cont = delta_plot_data[\n",
    "                        delta_plot_data[xvar].str.contains(\n",
    "                            i[i.index(j) - 1]\n",
    "                        )\n",
    "                    ].reset_index(drop=True)\n",
    "                delta_df = temp_df_exp.copy()\n",
    "                delta_df[yvar] = temp_df_exp[yvar] - temp_df_cont[yvar]\n",
    "                final_deltas = pd.concat([final_deltas, delta_df])\n",
    "    \n",
    "    return final_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2cd4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testingforPCA(n, df_sp, df_bsp, df_f, df_h, df_dispp, df_maxv, df_sim, alltgtmeandf_bout, alltgtnumberdf_bout, count):\n",
    "    totaldf = pd.DataFrame()\n",
    "       \n",
    "    totaldf[\"Bout speed\"] = new_deltav(df_bsp, \"BSpeed\")[new_deltav(df_bsp, \"BSpeed\")['TypeExperimentState']==\"Full Expt\"]['BSpeed'].reset_index(drop=True)\n",
    "    totaldf[\"Speed\"] = new_deltav(df_sp, \"Velocity\")[new_deltav(df_sp, \"Velocity\")['TypeExperimentState']==\"Full Expt\"]['Velocity'].reset_index(drop=True)\n",
    "    totaldf[\"Fall #\"] = new_deltav(df_f, \"Fall\")[new_deltav(df_f, \"Fall\")['TypeExperimentState']==\"Full Expt\"]['Fall'].reset_index(drop=True)\n",
    "    totaldf[\"Height\"] = new_deltav(df_h, \"Y\")[new_deltav(df_h, \"Y\")['TypeExperimentState']==\"Full Expt\"]['Y'].reset_index(drop=True)\n",
    "    totaldf[\"Mean Bout\"] = new_deltav(alltgtmeandf_bout, \"Bouts\")[new_deltav(alltgtmeandf_bout, \"Bouts\")['TypeExperimentState']==\"Full Expt\"]['Bouts'].reset_index(drop=True)\n",
    "    totaldf[\"Bout #\"] = new_deltav(alltgtnumberdf_bout, \"Bouts\")[new_deltav(alltgtnumberdf_bout, \"Bouts\")['TypeExperimentState']==\"Full Expt\"]['Bouts'].reset_index(drop=True)    \n",
    "    totaldf[\"Max velocity\"] = new_deltav(df_maxv, \"maxvelocity\")[new_deltav(df_maxv, \"maxvelocity\")['TypeExperimentState']==\"Full Expt\"]['maxvelocity'].reset_index(drop=True)\n",
    "    totaldf[\"Avg Straightness index\"] = new_deltav(df_sim, \"averagestraightnessindex\")[new_deltav(df_sim, \"averagestraightnessindex\")['TypeExperimentState']==\"Full Expt\"]['averagestraightnessindex'].reset_index(drop=True)\n",
    "    totaldf[\"displacement between pause\"] = new_deltav(df_dispp, \"avgdisplacementbetweenpause\")[new_deltav(df_dispp, \"avgdisplacementbetweenpause\")['TypeExperimentState']==\"Full Expt\"]['avgdisplacementbetweenpause'].reset_index(drop=True)\n",
    "    totaldf['MBON'] = n\n",
    "    totaldf = totaldf.set_index(['MBON'])\n",
    "    totaldf['number'] = count\n",
    "\n",
    "    return totaldf\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d6da4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "totaldf = pd.DataFrame()\n",
    "count = 0\n",
    "for n in lst:\n",
    "    count +=1\n",
    "    transgenic = n + \" x \" + responder\n",
    "    filename = openPath + transgenic + \".csv\"\n",
    "    filenamewt = openPath + wt+\"_\"+ transgenic + \".csv\"\n",
    "\n",
    "    dfe=pd.read_csv(filename)\n",
    "    dfw= pd.read_csv(filenamewt)\n",
    "\n",
    "    exptdf = dfe.drop(dfe.columns[[0]],axis = 1)\n",
    "    wtdf = dfw.drop(dfw.columns[[0]],axis = 1)\n",
    "\n",
    "    #adjust this depending on timeframe\n",
    "    dfexpt = NLCLIMB.fivesecondrule(NLCLIMB.generation(exptdf, n))\n",
    "    dfwt = NLCLIMB.fivesecondrule(NLCLIMB.generation(wtdf, wt))\n",
    "\n",
    "    df_sp = NLMATH.ospeed(dfwt, dfexpt).reset_index(drop=True)\n",
    "    df_bsp = NLMATH.bspeed(NLMATH.boutspeed(dfexpt), NLMATH.boutspeed(dfwt)).reset_index(drop=True)\n",
    "    df_f = NLMATH.fallingocc(dfexpt, dfwt).reset_index(drop=True)\n",
    "    df_h = NLMATH.totalheight(dfexpt, dfwt).reset_index(drop=True)\n",
    "\n",
    "    #newadditions\n",
    "    df_dispp = pd.concat([NLMATH.displacementbetweenpauses(dfexpt, \"Expt\"), NLMATH.displacementbetweenpauses(dfwt, \"WT\")], axis = 0).reset_index(drop=False)\n",
    "    df_maxv = pd.concat([NLMATH.maxvelocity(dfexpt, \"Expt\"), NLMATH.maxvelocity(dfwt, \"WT\")], axis = 0).reset_index(drop=False)\n",
    "    df_sim = pd.concat([NLMATH.straightnessindexmeter(dfexpt, \"Expt\"), NLMATH.straightnessindexmeter(dfwt, \"WT\")], axis = 0).reset_index(drop=True)\n",
    "\n",
    "    #pause and bouts\n",
    "    wttotalmeanevent, wttotalnumberevent = NLMATH.pausecomp(dfwt, wt)\n",
    "    expttotalmeanevent, expttotalnumberevent = NLMATH.pausecomp(dfexpt, n)\n",
    "        \n",
    "    #alltgtmeandf_pause = pd.concat([NLMATH.pausenumber(wttotalmeanevent, n, \"Pauses\"), NLMATH.pausenumber(expttotalmeanevent, n, \"Pauses\")], axis = 0).reset_index(drop=True)\n",
    "    alltgtmeandf_bout = pd.concat([NLMATH.pausenumber(wttotalmeanevent, n, \"Bouts\"), NLMATH.pausenumber(expttotalmeanevent, n, \"Bouts\")], axis = 0).reset_index(drop=True)\n",
    "\n",
    "    #alltgtnumberdf_pause = pd.concat([NLMATH.pausenumber(wttotalnumberevent, n, \"Pauses\"), NLMATH.pausenumber(expttotalnumberevent, n, \"Pauses\")], axis = 0).reset_index(drop=True)\n",
    "    alltgtnumberdf_bout = pd.concat([NLMATH.pausenumber(wttotalnumberevent, n, \"Bouts\"), NLMATH.pausenumber(expttotalnumberevent, n, \"Bouts\")], axis = 0).reset_index(drop=True)\n",
    "    \n",
    "    alltgtnumberdf_bout['genre'] = alltgtnumberdf_bout['ExperimentState'] + \" \" + alltgtnumberdf_bout['Type']\n",
    "    alltgtmeandf_bout['genre'] = alltgtnumberdf_bout['ExperimentState'] + \" \" + alltgtnumberdf_bout['Type']\n",
    "    \n",
    "    totaldf = pd.concat([totaldf, testingforPCA(n, df_sp, df_bsp, df_f, df_h, df_dispp, df_maxv, df_sim, alltgtmeandf_bout, alltgtnumberdf_bout, count)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47cb7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "totaldf.to_csv(openPath + \"Compilation with delta\\\\\" + date + \"pairedplotdeltawithmetrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "totaldf1 = totaldf.dropna()\n",
    "pca = PCA()\n",
    "components = pca.fit_transform(totaldf1[totaldf1.columns[:-1]])\n",
    "labels = {\n",
    "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "}\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    labels=labels,\n",
    "    dimensions=range(4),\n",
    "    color=totaldf1[\"number\"], width = 800, height = 800\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False, marker =dict(size = 3) )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=9)\n",
    "components = pca.fit_transform(totaldf1[totaldf1.columns[:-1]])\n",
    "\n",
    "total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "\n",
    "labels = {str(i): f\"PC {i+1}\" for i in range(9)}\n",
    "labels['color'] = 'Median Price'\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    color=totaldf1[\"number\"],\n",
    "    dimensions=range(9),\n",
    "    labels=labels,\n",
    "    title=f'Total Explained Variance: {total_var:.2f}%', width = 1200, height = 1200\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False, marker =dict(size = 3))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e699b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA covariance explained\n",
    "totaldf1 = totaldf.dropna()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "scaled_df = std_scaler.fit_transform(totaldf1)\n",
    "\n",
    "nums = np.arange(9)\n",
    "var_ratio = []\n",
    "for num in nums:\n",
    "  pca = PCA(n_components=num)\n",
    "  pca.fit(scaled_df)\n",
    "  var_ratio.append(np.sum(pca.explained_variance_ratio_))\n",
    "  \n",
    "plt.figure(figsize=(4,4),dpi=150)\n",
    "plt.grid()\n",
    "plt.plot(nums,var_ratio,marker='o')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.title('n_components vs. Explained Variance Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0c8ab",
   "metadata": {},
   "source": [
    "# run if new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1714d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa91313",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [\"SS67741\"] #lst but always be in list form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in dflists2:\n",
    "    globals()[j]=pd.DataFrame()\n",
    "    \n",
    "diff = pd.DataFrame()\n",
    "diffbs = pd.DataFrame()\n",
    "\n",
    "for n in lst:\n",
    "    driver = n\n",
    "    transgenic = driver + \" x \" + responder\n",
    "    filename = openPath + transgenic + \".csv\"\n",
    "    filenamewt = openPath + wt+\"_\"+ transgenic + \".csv\"\n",
    "\n",
    "    dfe=pd.read_csv(filename)\n",
    "    dfw= pd.read_csv(filenamewt)\n",
    "\n",
    "    exptdf = dfe.drop(dfe.columns[[0]],axis = 1)\n",
    "    wtdf = dfw.drop(dfw.columns[[0]],axis = 1)\n",
    "\n",
    "    #adjust this depending on timeframe\n",
    "    dfexpt = NLCLIMB.fivesecondrule(NLCLIMB.generation(exptdf, driver))\n",
    "    dfwt = NLCLIMB.fivesecondrule(NLCLIMB.generation(wtdf, wt))\n",
    "        \n",
    "    \n",
    "    df_sp = NLMATH.ospeed(dfwt, dfexpt).reset_index(drop=True)\n",
    "    df_bsp = NLMATH.bspeed(NLMATH.boutspeed(dfexpt), NLMATH.boutspeed(dfwt)).reset_index(drop=True)\n",
    "    df_t = NLMATH.timetype(dfwt, dfexpt).reset_index(drop=True)\n",
    "    df_f = NLMATH.fallingocc(dfexpt, dfwt).reset_index(drop=True)\n",
    "    df_h = NLMATH.totalheight(dfexpt, dfwt).reset_index(drop=True)\n",
    "    df_d = pd.concat([NLMATH.totaldisp(dfexpt, \"Expt\"), NLMATH.totaldisp(dfwt, \"WT\")]).reset_index(drop=True)\n",
    "    df_bp = NLMATH.bheight(NLMATH.boutheight(dfexpt), NLMATH.boutheight(dfwt)).reset_index(drop=True)\n",
    "    df_pp = NLMATH.bheight(NLMATH.pauseheight(dfexpt), NLMATH.pauseheight(dfwt)).reset_index(drop=True)\n",
    "    \n",
    "    #newadditions\n",
    "    df_dispp = pd.concat([NLMATH.displacementbetweenpauses(dfexpt, \"Expt\"), NLMATH.displacementbetweenpauses(dfwt, \"WT\")], axis = 0).reset_index(drop=False)\n",
    "    df_maxv = pd.concat([NLMATH.maxvelocity(dfexpt, \"Expt\"), NLMATH.maxvelocity(dfwt, \"WT\")], axis = 0).reset_index(drop=False)\n",
    "    df_sim = pd.concat([NLMATH.straightnessindexmeter(dfexpt, \"Expt\"), NLMATH.straightnessindexmeter(dfwt, \"WT\")], axis = 0).reset_index(drop=True)\n",
    "    \n",
    "    #pause and bouts\n",
    "    wttotalmeanevent, wttotalnumberevent = NLMATH.pausecomp(dfwt, wt)\n",
    "    expttotalmeanevent, expttotalnumberevent = NLMATH.pausecomp(dfexpt, driver)\n",
    "        \n",
    "    alltgtmeandf_pause = pd.concat([NLMATH.pausenumber(wttotalmeanevent, n, \"Pauses\"), NLMATH.pausenumber(expttotalmeanevent, n, \"Pauses\")], axis = 0).reset_index(drop=True)\n",
    "    alltgtmeandf_bout = pd.concat([NLMATH.pausenumber(wttotalmeanevent, n, \"Bouts\"), NLMATH.pausenumber(expttotalmeanevent, n, \"Bouts\")], axis = 0).reset_index(drop=True)\n",
    "    \n",
    "    alltgtnumberdf_pause = pd.concat([NLMATH.pausenumber(wttotalnumberevent, n, \"Pauses\"), NLMATH.pausenumber(expttotalnumberevent, n, \"Pauses\")], axis = 0).reset_index(drop=True)\n",
    "    alltgtnumberdf_bout = pd.concat([NLMATH.pausenumber(wttotalnumberevent, n, \"Bouts\"), NLMATH.pausenumber(expttotalnumberevent, n, \"Bouts\")], axis = 0).reset_index(drop=True)\n",
    "            \n",
    "    #deltaG plots\n",
    "    dfs2 = NLMATH.deltaversion(df_sp, n, \"Velocity\")\n",
    "    dft2 = NLMATH.deltaversion(df_t, n, \"Time\")\n",
    "    dff2 = NLMATH.deltaversion(df_f, n, \"Fall\")\n",
    "    dfh2 = NLMATH.deltaversion(df_h, n, \"Y\")\n",
    "    dfd2 = NLMATH.deltaversion(df_d, n, \"displacement\")\n",
    "    dfbs2 = NLMATH.deltaversion(df_bsp, n, \"BSpeed\")\n",
    "    dfbp2 = NLMATH.deltaversion(df_bp, n, \"Height\")\n",
    "    dfpp2 = NLMATH.deltaversion(df_pp, n, \"Height\")\n",
    "    \n",
    "    #new additions\n",
    "    dfdbp2 = NLMATH.deltaversion(df_dispp, n, \"avgdisplacementbetweenpause\")\n",
    "    dfmv2 = NLMATH.deltaversion(df_maxv, n, \"maxvelocity\")\n",
    "    dfsim2 = NLMATH.deltaversion(df_sim, n, \"averagestraightnessindex\")\n",
    "    \n",
    "    #pause and bouts\n",
    "    dfmp2 = NLMATH.deltaversion(alltgtmeandf_pause, n, \"Pauses\")\n",
    "    dfmb2 = NLMATH.deltaversion(alltgtmeandf_bout, n, \"Bouts\")     \n",
    "    dfnp2 = NLMATH.deltaversion(alltgtnumberdf_pause, n, \"Pauses\")\n",
    "    dfnb2 = NLMATH.deltaversion(alltgtnumberdf_bout, n, \"Bouts\")\n",
    "    \n",
    "\n",
    "    #regressiondfs\n",
    "    dfreg_speed = pd.concat([dfreg_speed, dfs2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_time = pd.concat([dfreg_time, dft2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_fall = pd.concat([dfreg_fall, dff2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_height = pd.concat([dfreg_height, dfh2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_displacement = pd.concat([dfreg_displacement, dfd2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_bspeed = pd.concat([dfreg_bspeed, dfbs2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_boutpos = pd.concat([dfreg_boutpos, dfbp2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_pausepos = pd.concat([dfreg_pausepos, dfpp2], axis = 0).reset_index(drop=True)\n",
    "    \n",
    "    dfreg_pause = pd.concat([dfreg_pause, dfnp2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_meanpause = pd.concat([dfreg_meanpause, dfmp2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_bout = pd.concat([dfreg_bout, dfnb2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_meanbout = pd.concat([dfreg_meanbout, dfmb2], axis = 0).reset_index(drop=True)\n",
    "    \n",
    "    dfreg_displacementbetweenpause = pd.concat([dfreg_displacementbetweenpause, dfdbp2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_maxvelocity = pd.concat([dfreg_maxvelocity, dfmv2], axis = 0).reset_index(drop=True)\n",
    "    dfreg_straightindex = pd.concat([dfreg_straightindex, dfsim2], axis = 0).reset_index(drop=True)\n",
    "    \n",
    "    df2list = [eval(xi) for xi in dflists2]\n",
    "\n",
    "    for nn in df2list:\n",
    "        nn.set_index(\"MBON\", inplace = True)\n",
    "        nn.to_csv(openPath + \"Compilation with delta\\\\2024collection\\\\\" + n + \" x \" + responder + \" \" + get_df_name(nn) + \" .csv\")\n",
    "        \n",
    "    print (n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d3646",
   "metadata": {},
   "source": [
    "# run if old files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d062083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_heatmapdf(responder):\n",
    "    \n",
    "    newfile2 = openPath + \"Compilation with delta\\\\2024collection\\\\\"\n",
    "    files2 = os.listdir(newfile2)\n",
    "\n",
    "    for labels in dflists2:\n",
    "        newfileread = pd.DataFrame()\n",
    "        for yy in files2:\n",
    "            if yy.split(\" \")[3] == labels and responder in yy:\n",
    "                newfile2read = pd.read_csv(newfile2 + yy)\n",
    "                newfileread = pd.concat([newfileread, newfile2read])\n",
    "        globals()[labels] = (newfileread.set_index(\"MBON\"))\n",
    "        \n",
    "    #generating list of MBONS\n",
    "    MBONList = []\n",
    "    for yy in files2:\n",
    "        MBONList.append(yy.split(\" \")[0])\n",
    "\n",
    "    MBONList = list(set(MBONList))\n",
    "    \n",
    "    #processing\n",
    "    dfreg2 = pd.DataFrame()\n",
    "    for n in MBONList:\n",
    "        dfreg = pd.DataFrame()\n",
    "        dfreg[\"Bout speed\"] = dfreg_bspeed[dfreg_bspeed.index == n]['delta_g']\n",
    "        dfreg[\"Speed\"] = dfreg_speed[dfreg_speed.index == n]['delta_g']\n",
    "        dfreg[\"Fall #\"] = dfreg_fall[dfreg_fall.index == n]['delta_g']\n",
    "        dfreg[\"Height\"] = dfreg_height[dfreg_height.index == n]['delta_g']\n",
    "        #dfreg[\"Time to reach 3/4 chamber\"] = dfreg_time[dfreg_time.index == n]['delta_g']\n",
    "        # dfreg[\"Mean\\n Pause\"] = dfreg_meanpause[dfreg_meanpause.index == n]['delta_g']\n",
    "        # dfreg[\"Pause #\"] = dfreg_pause[dfreg_pause.index == n]['delta_g']\n",
    "        dfreg[\"Mean Bout\"] = dfreg_meanbout[dfreg_meanbout.index == n]['delta_g']\n",
    "        dfreg[\"Bout #\"] = dfreg_bout[dfreg_bout.index == n]['delta_g']\n",
    "        #dfreg[\"Bout position\"] = dfreg_boutpos[dfreg_boutpos.index == n]['delta_g']\n",
    "        # dfreg[\"Pause\\n position\"] = dfreg_pausepos[dfreg_pausepos.index == n]['delta_g']\n",
    "        #new features\n",
    "        dfreg[\"Max velocity\"] = dfreg_maxvelocity[dfreg_maxvelocity.index == n]['delta_g']\n",
    "        dfreg[\"Avg Straightness index\"] = dfreg_straightindex[dfreg_straightindex.index == n]['delta_g']\n",
    "        dfreg[\"displacement between pause\"] = dfreg_displacementbetweenpause[dfreg_displacementbetweenpause.index == n]['delta_g']\n",
    "        dfreg['MBON'] = n\n",
    "        dfreg2 = pd.concat([dfreg2, dfreg], axis = 0).reset_index(drop=True)\n",
    "        \n",
    "    return dfreg2\n",
    "\n",
    "def find_number(df, lookup_value, genre):\n",
    "    lobe_values = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Splitting the 'MBON' values and removing any potential whitespace\n",
    "        mbon_values = [x.strip() for x in row['MBON names'].split(',')]\n",
    "        if lookup_value in mbon_values:\n",
    "            lobe_values.append(row[genre])\n",
    "            \n",
    "    lobelobe = list(set(lobe_values))\n",
    "    return ', '.join(lobelobe)\n",
    "\n",
    "def matchingdfs (df, matchingset):\n",
    "    newdf_a = pd.DataFrame()\n",
    "    for n in matchingset:\n",
    "        df_a=pd.DataFrame()\n",
    "        df_a = df[(df['MBON'] == n)]\n",
    "        newdf_a = pd.concat([newdf_a, df_a]).reset_index(drop=True)\n",
    "    return newdf_a\n",
    "\n",
    "import textwrap\n",
    "\n",
    "def wrap_labels(ax, width, break_long_words=False):\n",
    "    labels = []\n",
    "    for label in ax.get_xticklabels():\n",
    "        text = label.get_text()\n",
    "        labels.append(textwrap.fill(text, width=width,\n",
    "                      break_long_words=break_long_words))\n",
    "    ax.set_xticklabels(labels, rotation=0)\n",
    "    \n",
    "def matchinglobesets(dfreg_a, lobelocation):\n",
    "    lobelocation_a = lobelocation.sort_values(by=['MBON']).reset_index(drop=True)\n",
    "    dfreg_a_withloc = dfreg_a.sort_values(by=['MBON']).reset_index(drop=True)\n",
    "    matchinglobereg = list(set(lobelocation_a['MBON']) & set(dfreg_a_withloc['MBON']))\n",
    "\n",
    "    dflobe_reg = matchingdfs(lobelocation_a, matchinglobereg).sort_values(by=['MBON']).reset_index(drop=True)\n",
    "\n",
    "    dfreg_a_withloc['Lobe_location'] = dflobe_reg['Lobe_location']\n",
    "    dfreg_a_withloc['MBON number'] = dflobe_reg['MBON number']\n",
    "    dfreg_a_withloc['Neurotransmitter'] = dflobe_reg['Neurotransmitter']\n",
    "\n",
    "    return dfreg_a_withloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3636749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreg_ACR = generating_heatmapdf(\"ACR\").sort_values('MBON').reset_index(drop=True)\n",
    "dfreg_Cr2 = generating_heatmapdf(\"Chrimson2\").sort_values('MBON').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SPEED: sorting lists, arranging in ascending order\n",
    "\n",
    "# diff_sorted=diff.sort_values(by = \"delta_g\", ascending=True)\n",
    "# sortedindex = diff_sorted.index.tolist()\n",
    "# dblist= pd.DataFrame()\n",
    "# dblist['MBON'] = sortedinde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4c31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lobe location\n",
    "\n",
    "newfile2 = openPath + \"Compilation with delta\\\\2024collection\\\\\"\n",
    "files2 = os.listdir(newfile2)\n",
    "\n",
    "MBONList = []\n",
    "for yy in files2:\n",
    "    MBONList.append(yy.split(\" \")[0])\n",
    "\n",
    "MBONList = list(set(MBONList))\n",
    "\n",
    "#reading mbonlist file\n",
    "directorynew = os.path.dirname(os.path.dirname(openPath)) #goes up one directory\n",
    "fileinnewdirc = os.listdir(directorynew)\n",
    "\n",
    "for file_no2 in fileinnewdirc:\n",
    "    if \".csv\" in file_no2:\n",
    "        ff = os.path.join(directorynew, file_no2)\n",
    "        csvfile = pd.read_csv(ff)\n",
    "\n",
    "csvfile = csvfile.astype('string')\n",
    "\n",
    "for n, k in zip([\"B\", \"y\", \"a\"], ['β', \"γ\", \"α\"]):\n",
    "    csvfile['Lobe'] = csvfile['Lobe'].str.replace(n, k)\n",
    "\n",
    "lobelocation = pd.DataFrame()\n",
    "\n",
    "for m in MBONList:\n",
    "    lobeloc = pd.DataFrame()\n",
    "    unqlist = []\n",
    "    lobeloc['MBON'] = [m]\n",
    "    loclst = find_number(csvfile, m, \"Lobe\")\n",
    "    mbonlst = find_number(csvfile, m, \"MBON number\")\n",
    "    ntlst = find_number(csvfile, m, \"Neurotransmitter\")\n",
    "    lobeloc['Lobe_location'] = [loclst]\n",
    "    lobeloc['MBON number'] = [mbonlst]\n",
    "    lobeloc['Neurotransmitter'] = [ntlst]\n",
    "    \n",
    "    lobelocation = pd.concat([lobelocation, lobeloc])\n",
    "\n",
    "lobelocation = lobelocation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822eb8e7",
   "metadata": {},
   "source": [
    "## heatmap with ACR2 and Chrimson2 differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab053b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchingset = list(set(dfreg_ACR['MBON']) & set(dfreg_Cr2['MBON']))\n",
    "\n",
    "dfreg_a = matchingdfs(dfreg_ACR, matchingset)\n",
    "dfreg_c = matchingdfs(dfreg_Cr2, matchingset)\n",
    "\n",
    "dfreg_a['responder'] = dfreg_a['MBON']+\"_A\"\n",
    "dfreg_c['responder'] = dfreg_c['MBON']+\"_C\"\n",
    "\n",
    "dfreg_resp = pd.concat([dfreg_a, dfreg_c])\n",
    "\n",
    "dfreg_resp = dfreg_resp.sort_values(by = \"responder\", ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79129c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df00 = dfreg_resp.copy()\n",
    "df50 = df00.set_index(['responder'])\n",
    "df50 = df50.drop(['MBON'], axis =1)\n",
    "\n",
    "\n",
    "\n",
    "fig1, ax3 = plt.subplots(figsize=(10, 18))     \n",
    "\n",
    "#adding extra axes label\n",
    "lobloclst = []\n",
    "mbonloclst = []\n",
    "for n in dfreg_resp['MBON']:\n",
    "    df500 = dfreg_resp.copy()\n",
    "    lobloclst.append(lobelocation[lobelocation['MBON'] == n]['Lobe_location'].values[0])\n",
    "    mbonloclst.append(lobelocation[lobelocation['MBON'] == n]['MBON number'].values[0])\n",
    "df500['Lobe'] = lobloclst\n",
    "df500['Name'] = mbonloclst\n",
    "\n",
    "newdf500 = pd.DataFrame()\n",
    "naming = df500['Name'].iloc[::2].to_frame().rename(columns = {\"Name\": \"\"})\n",
    "lobing = df500['Lobe'].iloc[1::2].to_frame().rename(columns = {\"Lobe\": \"\"})\n",
    "newdf500['Merge'] = pd.concat([naming,  lobing]).sort_index()\n",
    "\n",
    "#colorbar\n",
    "cax = inset_axes(ax3,\n",
    "                 width=\"15%\",  # width: 40% of parent_bbox width\n",
    "                 height=\"2%\",  # height: 10% of parent_bbox height\n",
    "                 loc='lower right',\n",
    "                 bbox_to_anchor=(0.1, 1.05, 1, 1),\n",
    "                 bbox_transform=ax3.transAxes,\n",
    "                 borderpad=-2,\n",
    "                 )\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})           \n",
    "j7 = sns.heatmap(df50, ax = ax3, annot=True, fmt=\".1f\", vmin = -1.5, vmax = 1.5, cmap='coolwarm', linewidths=0.0, edgecolor = \"none\"\n",
    "                 , clip_on=False, cbar_ax=cax, cbar_kws = dict(orientation = \"horizontal\")) #use_gridspec=False,location=\"bottom\", shrink = 0.25, pad=0.01 #cbar_kws = dict(orientation = \"vertical\")\n",
    "j7.set_ylabel('')\n",
    "j7.set_yticklabels(j7.get_yticklabels(), va='center', rotation = 0, fontsize = 10)\n",
    "j7.set_xticklabels(j7.get_xticklabels(), rotation = 0, fontsize = 10)\n",
    "\n",
    "wrap_labels(j7, 10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "for i in list(range(0,92,2)):\n",
    "    ax3.add_patch(Rectangle((0, i), 9, 2, fill=False, edgecolor='black', lw=2))\n",
    "\n",
    "# Drawing the frame \n",
    "j7.axhline(y = 0, color = 'k',  \n",
    "            linewidth = 5) \n",
    "  \n",
    "j7.axhline(y = 44, color = 'k', \n",
    "            linewidth = 5) \n",
    "  \n",
    "j7.axvline(x = 0, color = 'k', \n",
    "            linewidth = 5) \n",
    "  \n",
    "j7.axvline(x = 9, color = 'k', \n",
    "            linewidth = 5) \n",
    "\n",
    "#secondary axes\n",
    "j8 = j7.twinx()\n",
    "j8.set_ylim([0,j7.get_ylim()[0]])\n",
    "j8.set_yticks(j7.get_yticks())\n",
    "\n",
    "j8.set_yticklabels(newdf500['Merge'].iloc[::-1], fontsize=10)\n",
    "j8.spines['top'].set_visible(False)\n",
    "j8.spines['right'].set_visible(False)\n",
    "j8.spines['bottom'].set_visible(False)\n",
    "j8.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "j7.set_title('Plot of MBONs and their Δg across locomotor reactivity parameters', x=0.4, weight='bold', fontsize =13 )\n",
    "\n",
    "fig1.tight_layout()\n",
    "\n",
    "plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_deltagheatmapwithlobelocations.png\", dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e0de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini list\n",
    "\n",
    "lstofmbonsiwant = MBONList\n",
    "df_specificmbon = pd.DataFrame()\n",
    "for n in lstofmbonsiwant:\n",
    "    df_specificmbon = pd.concat([df_specificmbon, dfreg_resp[dfreg_resp['MBON'] == n]])\n",
    "    \n",
    "df_specificmbon = df_specificmbon.reset_index(drop=True)\n",
    "df60 = df_specificmbon.set_index(['responder'])\n",
    "df60 = df60.drop(['MBON'], axis =1)\n",
    "fig1, ax3 = plt.subplots(figsize=(8, 10))     \n",
    "\n",
    "#adding extra axes label\n",
    "lobloclst = []\n",
    "mbonloclst = []\n",
    "for n in df_specificmbon['MBON']:\n",
    "    df600 = df_specificmbon.copy()\n",
    "    lobloclst.append(lobelocation[lobelocation['MBON'] == n]['Lobe_location'].values[0])\n",
    "    mbonloclst.append(lobelocation[lobelocation['MBON'] == n]['MBON number'].values[0])\n",
    "df600['Lobe'] = lobloclst\n",
    "df600['Name'] = mbonloclst\n",
    "\n",
    "newdf600 = pd.DataFrame()\n",
    "naming = df600['Name'].iloc[::2].to_frame().rename(columns = {\"Name\": \"\"})\n",
    "lobing = df600['Lobe'].iloc[1::2].to_frame().rename(columns = {\"Lobe\": \"\"})\n",
    "newdf600['Merge'] = pd.concat([naming,  lobing]).sort_index()\n",
    "\n",
    "#colorbar\n",
    "cax = inset_axes(ax3,\n",
    "                 width=\"15%\",  # width: 40% of parent_bbox width\n",
    "                 height=\"2%\",  # height: 10% of parent_bbox height\n",
    "                 loc='lower right',\n",
    "                 bbox_to_anchor=(0.2, 1.5, 1, 1),\n",
    "                 bbox_transform=ax3.transAxes,\n",
    "                 borderpad=-2,\n",
    "                 )\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})           \n",
    "j7 = sns.heatmap(df60, ax = ax3, annot=True, fmt=\".1f\", vmin = -1.5, vmax = 1.5, cmap='coolwarm', linewidths=0.0, edgecolor = \"none\"\n",
    "                 , clip_on=False, cbar_ax=cax, cbar_kws = dict(orientation = \"horizontal\")) #use_gridspec=False,location=\"bottom\", shrink = 0.25, pad=0.01 #cbar_kws = dict(orientation = \"vertical\")\n",
    "j7.set_ylabel('')\n",
    "j7.set_yticklabels(j7.get_yticklabels(), va='center', rotation = 0, fontsize = 10)\n",
    "j7.set_xticklabels(j7.get_xticklabels(), rotation = 0, fontsize = 10)\n",
    "\n",
    "wrap_labels(j7, 10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "for i in list(range(0,46,2)):\n",
    "    ax3.add_patch(Rectangle((0, i), 9, 2, fill=False, edgecolor='black', lw=2))\n",
    "\n",
    "# Drawing the frame \n",
    "j7.axhline(y = 0, color = 'k',  \n",
    "            linewidth = 5) \n",
    "  \n",
    "j7.axhline(y = 44, color = 'k', \n",
    "            linewidth = 5) \n",
    "  \n",
    "j7.axvline(x = 0, color = 'k', \n",
    "            linewidth = 5) \n",
    "  \n",
    "j7.axvline(x = 9, color = 'k', \n",
    "            linewidth = 5) \n",
    "\n",
    "#secondary axes\n",
    "j8 = j7.twinx()\n",
    "j8.set_ylim([0,j7.get_ylim()[0]])\n",
    "j8.set_yticks(j7.get_yticks())\n",
    "\n",
    "j8.set_yticklabels(newdf600['Merge'].iloc[::-1], fontsize=10)\n",
    "j8.spines['top'].set_visible(False)\n",
    "j8.spines['right'].set_visible(False)\n",
    "j8.spines['bottom'].set_visible(False)\n",
    "j8.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "#j7.set_title('Plot of MBONs and their Δg across locomotor reactivity parameters', x=0.5, weight='bold', fontsize =13 )\n",
    "\n",
    "fig1.tight_layout()\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_deltagheatmapwithlobelocations_forfirst10s.png\", dpi = 1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdc7646",
   "metadata": {},
   "source": [
    "## differenced heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861ff91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "effectsizediff = pd.DataFrame()\n",
    "for n in matchingset:\n",
    "    newt = dfreg_resp[dfreg_resp['MBON'] == n]\n",
    "    MBONlabel = pd.DataFrame()\n",
    "    MBONlabel['responder'] = [n]\n",
    "    newtdiff = newt.iloc[:,:-2].diff().abs().iloc[1:,:].reset_index(drop=True)\n",
    "\n",
    "    newton = pd.concat([MBONlabel, newtdiff], axis = 1)\n",
    "    effectsizediff = pd.concat([effectsizediff, newton]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23dae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "effectsizediff = effectsizediff.sort_values(by = \"responder\", ascending=True).reset_index(drop=True)\n",
    "df00 = effectsizediff.copy()\n",
    "df50 = df00.set_index(['responder'])\n",
    "fig1, ax3 = plt.subplots(figsize=(15, 8))     \n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})           \n",
    "j7 = sns.heatmap(df50, ax = ax3, annot=True, fmt=\".1f\", vmin = 0, vmax = 2.5, cmap='YlGnBu', linewidths=0.0, edgecolor = \"none\"\n",
    "                 , clip_on=False, cbar_kws={\"shrink\": 0.5, \"pad\": 0.01}) #use_gridspec=False,location=\"bottom\", shrink = 0.25, pad=0.01 #cbar_kws = dict(orientation = \"vertical\")\n",
    "j7.set_ylabel('')\n",
    "j7.set_yticklabels(j7.get_yticklabels(), va='center', rotation = 0, fontsize = 10)\n",
    "j7.set_xticklabels(j7.get_xticklabels(), rotation = 0, fontsize = 10)\n",
    "\n",
    "wrap_labels(j7, 10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Drawing the frame \n",
    "j7.axhline(y = 0, color = 'k',  \n",
    "            linewidth = 5) \n",
    "  \n",
    "j7.axhline(y = 22, color = 'k', \n",
    "            linewidth = 5) \n",
    "  \n",
    "j7.axvline(x = 0, color = 'k', \n",
    "            linewidth = 5) \n",
    "  \n",
    "j7.axvline(x = 9, color = 'k', \n",
    "            linewidth = 5) \n",
    "\n",
    "j7.set_title('Plot of MBONs and the abs Δg difference between Chrimson2 and ACR', x=0.5, weight='bold', fontsize =13 )\n",
    "\n",
    "fig1.tight_layout()\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_deltagheatmapwithlobelocations_forfirst10s.png\", dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c43da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df80 = df00.set_index(['responder'])\n",
    "methodlist = ['average']\n",
    "metriclist = ['euclidean']\n",
    "\n",
    "for methodd in methodlist:\n",
    "    for metricc in metriclist:\n",
    "        print (methodd + \" \" + metricc)\n",
    "        j7 = sns.clustermap(df80, cmap='Blues', metric = metricc, method = methodd,vmin = 0, vmax=2.5, \n",
    "                            cbar_kws = dict(shrink = 0.2, ticks = [0, 2.5]), figsize=(10, 10), cbar_pos=(0, 0.84, .02, .1) ) #use_gridspec=False,location=\"bottom\", shrink = 0.25, pad=0.01\n",
    "        ax = j7.ax_heatmap\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation = 0, fontsize = 9)\n",
    "        wrap_labels(ax, 8)\n",
    "        j7.fig.suptitle('Clustermap using ' + methodd + \"_\" + metricc + ' : The Δg difference between Chrimson2 and ACR', weight='bold', fontsize =12, y =1.0)\n",
    "        \n",
    "        #plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_clustermap_\" + methodd + \"_\" + metricc + \"_\" + secondrule +\".png\", dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# lobeloc = specificmbonlist(lobelocation)\n",
    "dfreglobe =dfreg_ACR.copy()\n",
    "dfreglobe['Lobe'] = lobelocation['Lobe_location']\n",
    "dfreglobe['Name'] = lobelocation['MBON number']\n",
    "df00 = dfreglobe.copy()\n",
    "\n",
    "df50 = df00.set_index(['Name'])\n",
    "df50 = df50.drop(['MBON', 'Lobe'], axis =1)\n",
    "fig1, ax3 = plt.subplots(figsize=(16, 8))     \n",
    "#colorbar\n",
    "cax = inset_axes(ax3,\n",
    "                 width=\"15%\",  # width: 40% of parent_bbox width\n",
    "                 height=\"2%\",  # height: 10% of parent_bbox height\n",
    "                 loc='lower right',\n",
    "                 bbox_to_anchor=(0.1, 1.1, 1, 1),\n",
    "                 bbox_transform=ax3.transAxes,\n",
    "                 borderpad=-2,\n",
    "                 )\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})           \n",
    "j7 = sns.heatmap(df50, ax = ax3, annot=True, fmt=\".1f\", vmin = -1.5, vmax = 1.5, cmap='coolwarm', linewidths=0.5, linecolor='black'\n",
    "                 , clip_on=False,  cbar_ax=cax, cbar_kws = dict(orientation = \"horizontal\")) #use_gridspec=False,location=\"bottom\", shrink = 0.25, pad=0.01\n",
    "j7.set_ylabel('')\n",
    "j7.set_yticklabels(j7.get_yticklabels(), va='center', rotation = 0, fontsize = 12)\n",
    "j7.set_xticklabels(j7.get_xticklabels(), rotation = 0, fontsize = 12)\n",
    "\n",
    "#secondary axes\n",
    "j8 = j7.twinx()\n",
    "j8.set_ylim([0,j7.get_ylim()[0]])\n",
    "j8.set_yticks(j7.get_yticks())\n",
    "\n",
    "j8.set_yticklabels(df00['MBON'].iloc[::-1], fontsize=12)\n",
    "j8.spines['top'].set_visible(False)\n",
    "j8.spines['right'].set_visible(False)\n",
    "j8.spines['bottom'].set_visible(False)\n",
    "j8.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "wrap_labels(j7, 10)\n",
    "j7.set_title('Plot of MBONs > ' + responder + ' and their Δg across locomotor reactivity parameters for first 20seconds', x=0.4, weight='bold', fontsize =16 )\n",
    "\n",
    "# #fig1.tight_layout()\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_deltagheatmapwithlobelocations_forfirst10s.png\", dpi = 1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43b9a8",
   "metadata": {},
   "source": [
    "## linear regression via metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4409225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreg_a = matchingdfs(dfreg_ACR, matchingset)\n",
    "dfreg_c = matchingdfs(dfreg_Cr2, matchingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "fig2, ax2 = plt.subplots(nrows = 1, ncols = 9, figsize = (20, 3), sharey = True, layout= 'constrained')\n",
    "labels = [ ' \\n '.join(wrap(l, 12)) for l in dfreg_a.columns[:-2].tolist()]\n",
    "\n",
    "for c,(n,leg) in enumerate(zip(dfreg_a.columns[:-2].tolist(),8*[False]+[True])):\n",
    "    spare = pd.DataFrame()\n",
    "    spare[\"ACR\"] = matchinglobesets(dfreg_a, lobelocation)[n]\n",
    "    spare['Chrimson2'] = matchinglobesets(dfreg_c, lobelocation)[n]\n",
    "    spare['NT'] = matchinglobesets(dfreg_c, lobelocation)['Neurotransmitter']\n",
    "    sns.regplot(x=\"ACR\", y=\"Chrimson2\", data=spare, ci = 95, scatter = False, line_kws={\"color\": \"black\", 'lw': 1.5}, ax=ax2[c]) \n",
    "    sns.scatterplot(x=\"ACR\", y=\"Chrimson2\", data=spare, hue='NT', s = 3, ax = ax2[c], legend = leg)\n",
    "    ax2[c].set_xlim([-2,2])\n",
    "    ax2[c].set_ylim([-2,2])\n",
    "    ax2[c].set_xlabel(labels[c])\n",
    "    ax2[c].set_ylabel(\"\")\n",
    "    \n",
    "    #pearsons correlation\n",
    "    pearsonscorrelation = scipy.stats.pearsonr(dfreg_a[n], dfreg_c[n]) #correlation instead of linear regression: trying to find the relationship rather than causation    \n",
    "    civallow = pearsonscorrelation.confidence_interval(confidence_level=0.95)[0] \n",
    "    civalhigh = pearsonscorrelation.confidence_interval(confidence_level=0.95)[1]   \n",
    "    ax2[c].annotate(\"Coeff:\" + str(round(pearsonscorrelation[0],3)) + \"\\nCI:\" + str(round(civallow,3)) + \", \" + str(round(civalhigh,3)), (0.45, 0.8), ha = \"left\", xycoords = 'axes fraction', fontsize = 8)\n",
    "\n",
    "fig2.supxlabel(\"ACR\", weight = \"bold\")\n",
    "fig2.supylabel(\"Chrimson2\", weight = \"bold\")\n",
    "fig2.suptitle(\"Linear regression with Pearson's coeff\", fontsize = 16, weight=\"bold\")\n",
    "\n",
    "new_labels = ['Glutamate', 'Acetylcholine', 'GABA', 'Acetylcholine, GABA']\n",
    "legend_handles, _= ax2[c].get_legend_handles_labels()\n",
    "lgd = fig2.legend(legend_handles, new_labels, \n",
    "          bbox_to_anchor=(1,1), ncol = 4, frameon = False)\n",
    "ax2[c].get_legend().set_visible(False)\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_bidirectionalitycheck.png\", dpi = 1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876791f2",
   "metadata": {},
   "source": [
    "## linear regression grouped by circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6707b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from matplotlib.patches import Ellipse\n",
    "# fig3, axthree = plt.subplots(nrows = 1, ncols = 9, figsize = (20, 3), sharey = True, layout= 'constrained')\n",
    "\n",
    "\n",
    "for c,(n,leg) in enumerate(zip(dfreg_a.columns[:-2].tolist(),8*[False]+[True])):\n",
    "    fig3, axthree = plt.subplots(figsize = (4, 4))\n",
    "    \n",
    "    spare = pd.DataFrame()\n",
    "    spare[\"ACR\"] = matchinglobesets(dfreg_a, lobelocation)[n]\n",
    "    spare['Chrimson2'] = matchinglobesets(dfreg_c, lobelocation)[n]\n",
    "    spare['NT'] = matchinglobesets(dfreg_c, lobelocation)['Neurotransmitter']\n",
    "    \n",
    "    #kmeans\n",
    "    kmeans = SpectralClustering(n_clusters=3)\n",
    "    clusters = kmeans.fit_predict(spare.iloc[:,0:2])\n",
    "    cluster = ['k-means_c_' + str(c) for c in clusters]\n",
    "    X = spare.iloc[:,0:2]\n",
    "    ogdots = ['#d90429','#f7b267', '#89fc00', '#735751'] #neurotransmitters : red, orange, green, brown\n",
    "    clusterdots = [\"#03045e\", '#0077b6', \"#00b4d8\", \"#90e0ef\"] #clustering patterns :blue\n",
    "    \n",
    "    #neto = sns.scatterplot(x=\"ACR\", y=\"Chrimson2\", data=spare, hue='NT', s = 80, edgecolor = \"none\", palette = ogdots , legend = True)\n",
    "    sns.scatterplot(x=\"ACR\", y=\"Chrimson2\", data=X.iloc[:,0:2].assign(cluster = cluster), hue='cluster', palette = clusterdots, legend = False, s = 40, edgecolor = \"none\")\n",
    "           \n",
    "    axthree.set_xlim([-2,2])\n",
    "    axthree.set_ylim([-2,2])\n",
    "    axthree.set_xlabel(\"\")\n",
    "    axthree.set_ylabel(\"\")\n",
    "    plt.yticks(fontsize=6)\n",
    "    plt.xticks(fontsize=6)\n",
    "    \n",
    "\n",
    "    fig3.supxlabel(\"ACR\", fontsize = 8,  weight = \"bold\")\n",
    "    fig3.supylabel(\"Chrimson2\", fontsize = 8, weight = \"bold\")\n",
    "    fig3.suptitle(n, fontsize = 12, weight=\"bold\")\n",
    "    plt.legend(loc=2, prop={'size': 8})\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_bidirectionalitycheck.png\", dpi = 1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99375575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completeresponder = pd.concat([dfreg_a, dfreg_c])\n",
    "df_lregmbon = df_completeresponder.sort_values(['MBON']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88062e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "fig7, ax7 = plt.subplots(nrows = 5, ncols = 5, figsize = (10, 10), sharey = True, sharex = True, layout= 'constrained')\n",
    "for name,row,col in zip(dfreg_a['MBON'], 5*list(range(0,5)), 5*[0]+5*[1]+5*[2]+5*[3]+ 5*[4] +5*[5]):\n",
    "    df_meltedreg = pd.melt(df_lregmbon[(df_lregmbon['MBON'] == name)], id_vars = ['responder', \"MBON\"])   \n",
    "    df_a1= df_meltedreg[(df_meltedreg['responder'] == 'Cr2')]\n",
    "    df_c1=df_meltedreg[(df_meltedreg['responder'] == 'ACR')]\n",
    "    \n",
    "    ax7[row][col].scatter(x= df_a1['value'], y = df_c1['value'],\n",
    "                color='grey',\n",
    "                edgecolors=\"r\",\n",
    "                alpha=0.8,\n",
    "                s=30)\n",
    "    \n",
    "    sns.regplot(x= df_a1['value'], y = df_c1['value'],\n",
    "                scatter=False,\n",
    "                line_kws={'lw':1}, \n",
    "                color=\"k\",\n",
    "                ax=ax7[row][col],\n",
    "                truncate=False)\n",
    "\n",
    "    ax7[row][col].set(xlabel=None)\n",
    "    ax7[row][col].set(ylabel=None)\n",
    "    ax7[row][col].set_ylim(-2.1,2.1)  \n",
    "    ax7[row][col].set_xlim(-2.1,2.1) \n",
    "    ax7[row][col].set_title(name, fontsize = 12)\n",
    "\n",
    "    \n",
    "    #pearsons correlation\n",
    "    pearsonscorrelation = scipy.stats.pearsonr(df_a1['value'], df_c1['value']) #correlation instead of linear regression: trying to find the relationship rather than causation    \n",
    "    civallow = pearsonscorrelation.confidence_interval(confidence_level=0.95)[0] \n",
    "    civalhigh = pearsonscorrelation.confidence_interval(confidence_level=0.95)[1]\n",
    "    ax7[row][col].annotate(\"Coeff:\" + str(round(pearsonscorrelation[0],3)) + \"\\nCI:\" + str(round(civallow,3)) + \", \" + str(round(civalhigh,3)), (0.55, 0.8), ha = \"left\", xycoords = 'axes fraction', fontsize = 9)\n",
    "\n",
    "    \n",
    "fig7.supxlabel(\"ACR\", weight = \"bold\")\n",
    "fig7.supylabel(\"Chrimson2\", weight = \"bold\")\n",
    "fig7.suptitle(\"Linear regression with Pearson's coeff\", fontsize = 16, weight=\"bold\")\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_bidirectionalitycheckMBON.png\", dpi = 1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a16be",
   "metadata": {},
   "source": [
    "## scatter plot clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcae18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if responder == \"ACR\":\n",
    "    dfreglobe = dfreg_ACR\n",
    "    \n",
    "if responder == \"Chrimson2\":\n",
    "    dfreglobe = dfreg_Cr2\n",
    "\n",
    "dfreglobe['Lobe'] = lobelocation['Lobe_location']\n",
    "dfreglobe['Name'] = lobelocation['MBON number']\n",
    "dfreglobe['Neurotransmitter'] = lobelocation['Neurotransmitter']\n",
    "\n",
    "df00 = dfreglobe.copy()\n",
    "novt = df00[(df00['MBON']== \"VT999036\")].index\n",
    "df50 = df00.drop(novt)\n",
    "df50 = df50.drop(['MBON', 'Name', 'Lobe'], axis =1)\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "df89 = pd.melt(df50, id_vars = ['Neurotransmitter'], var_name = 'Metrics', value_name = \"Δg\")\n",
    "g1 = sns.swarmplot(data=df89, x= 'Metrics', y = 'Δg', hue='Neurotransmitter',dodge = True)\n",
    "sns.move_legend(g1, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "sns.set_style(\"darkgrid\")\n",
    "wrap_labels(axes, 10)\n",
    "g1.set_title('Plot of MBONs > ' + responder + ' and their Δg separated by neurotransmitter types according to locomotor metrics for first ' + secondrule, weight='bold', fontsize =12 )\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_separationbyNTtypes_\" + secondrule +\".png\", dpi = 1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b703ef2",
   "metadata": {},
   "source": [
    "## sns paired plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if responder == \"ACR\":\n",
    "    dfreglobe = dfreg_ACR\n",
    "    \n",
    "if responder == \"Chrimson2\":\n",
    "    dfreglobe = dfreg_Cr2\n",
    "\n",
    "dfreglobe['Lobe'] = lobelocation['Lobe_location']\n",
    "dfreglobe['Name'] = lobelocation['MBON number']\n",
    "dfreglobe['Neurotransmitter'] = lobelocation['Neurotransmitter']\n",
    "\n",
    "df00 = dfreglobe.copy()\n",
    "novt = df00[(df00['MBON']== \"VT999036\")].index\n",
    "df50 = df00.drop(novt)\n",
    "df50 = df50.drop(['MBON', 'Name', 'Lobe'], axis =1)\n",
    "\n",
    "t1 = sns.pairplot(data=df50, hue='Neurotransmitter')\n",
    "t1.fig.suptitle('MBONs > ' + responder, weight='bold', fontsize =16, y = 1.02 )\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_separationbyNTtypes_\" + secondrule +\".png\", dpi = 1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e1392",
   "metadata": {},
   "source": [
    "## clustermap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55714715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "if responder == \"ACR\":\n",
    "    dfreglobe = dfreg_ACR\n",
    "    \n",
    "if responder == \"Chrimson2\":\n",
    "    dfreglobe = dfreg_Cr2\n",
    "    \n",
    "dfreglobe['Lobe'] = lobelocation['Lobe_location']\n",
    "dfreglobe['Name'] = lobelocation['MBON number']\n",
    "dfreglobe['Neurotransmitter'] = lobelocation['Neurotransmitter']\n",
    "\n",
    "df00 = dfreglobe.copy()\n",
    "\n",
    "df50 = df00.set_index(['Lobe'])\n",
    "df50 = df50.drop(['MBON', 'Name', 'Neurotransmitter'], axis =1)\n",
    "methodlist = ['average']\n",
    "metriclist = ['euclidean']\n",
    "\n",
    "for methodd in methodlist:\n",
    "    for metricc in metriclist:\n",
    "        print (methodd + \" \" + metricc)\n",
    "        j7 = sns.clustermap(df50, cmap='coolwarm', metric = metricc, method = methodd,vmin = -1.5, vmax=1.5, \n",
    "                            cbar_kws = dict(shrink = 0.2, ticks = [-1.5, 1.5]), figsize=(10, 10), cbar_pos=(0, 0.82, .02, .1) ) #use_gridspec=False,location=\"bottom\", shrink = 0.25, pad=0.01\n",
    "        ax = j7.ax_heatmap\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation = 0, fontsize = 9)\n",
    "        wrap_labels(ax, 8)\n",
    "        #j7.fig.suptitle('Clustermap using ' + methodd + \"_\" + metricc + ' :MBONs > ' + responder + ' and their Δg', weight='bold', fontsize =12, y =1.0)\n",
    "        \n",
    "        #plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_clustermap_\" + methodd + \"_\" + metricc + \"_\" + secondrule +\".png\", dpi = 1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0cb9fa",
   "metadata": {},
   "source": [
    "## heatmap arranged by speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a73f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "if responder == \"ACR\":\n",
    "    dfreglobe = dfreg_ACR\n",
    "    \n",
    "if responder == \"Chrimson2\":\n",
    "    dfreglobe = dfreg_Cr2\n",
    "    \n",
    "lobloclst = []\n",
    "mbonloclst = []\n",
    "for n in dfreglobe['MBON']:\n",
    "    df500 = dfreglobe.copy()\n",
    "    lobloclst.append(lobelocation[lobelocation['MBON'] == n]['Lobe_location'].values[0])\n",
    "    mbonloclst.append(lobelocation[lobelocation['MBON'] == n]['MBON number'].values[0])\n",
    "df500['Lobe'] = lobloclst\n",
    "df500['Name'] = mbonloclst\n",
    "\n",
    "df50 = df500.set_index(['Name'])\n",
    "df50 = df50.drop(['MBON', 'Lobe'], axis =1)\n",
    "fig1, ax3 = plt.subplots(figsize=(14, 7))     \n",
    "#colorbar\n",
    "cax = inset_axes(ax3,\n",
    "                 width=\"15%\",  # width: 40% of parent_bbox width\n",
    "                 height=\"2%\",  # height: 10% of parent_bbox height\n",
    "                 loc='lower right',\n",
    "                 bbox_to_anchor=(0.1, 1.1, 1, 1),\n",
    "                 bbox_transform=ax3.transAxes,\n",
    "                 borderpad=-2,\n",
    "                 )\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})           \n",
    "j7 = sns.heatmap(df50, ax = ax3, annot=True, fmt=\".1f\", vmin = -1.5, vmax = 1.5, cmap='coolwarm', linewidths=0.5, linecolor='black'\n",
    "                 , clip_on=False,  cbar_ax=cax, cbar_kws = dict(orientation = \"horizontal\")) #use_gridspec=False,location=\"bottom\", shrink = 0.25, pad=0.01\n",
    "j7.set_ylabel('')\n",
    "j7.set_yticklabels(j7.get_yticklabels(), va='center', rotation = 0, fontsize = 10)\n",
    "j7.set_xticklabels(j7.get_xticklabels(), rotation = 0, fontsize = 12)\n",
    "\n",
    "#secondary axes\n",
    "j8 = j7.twinx()\n",
    "j8.set_ylim([0,j7.get_ylim()[0]])\n",
    "j8.set_yticks(j7.get_yticks())\n",
    "\n",
    "j8.set_yticklabels(df500['Lobe'].iloc[::-1], fontsize=10)\n",
    "j8.spines['top'].set_visible(False)\n",
    "j8.spines['right'].set_visible(False)\n",
    "j8.spines['bottom'].set_visible(False)\n",
    "j8.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "wrap_labels(j7, 10)\n",
    "j7.set_title('Plot of MBONs > ' + responder + ' and their Δg across locomotor reactivity parameters' , x=0.4, weight='bold', fontsize =16 )\n",
    "\n",
    "#fig1.tight_layout()\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_deltagheatmapwithlobelocations.png\", dpi = 1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e594f8",
   "metadata": {},
   "source": [
    "## simple heatmap version + delta version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple heatmap\n",
    "if responder == \"ACR\":\n",
    "    df55 = dfreg_ACR\n",
    "    \n",
    "if responder == \"Chrimson2\":\n",
    "    df55 = dfreg_Cr2\n",
    " \n",
    "df5 = df55.set_index(['MBON'])\n",
    "fig, ax1 = plt.subplots(figsize=(12, 2))                \n",
    "g1 = sns.heatmap(df5, annot=True, fmt=\".1f\", vmin = -1.5, vmax = 1.5, cmap='coolwarm', linewidths=0.5, linecolor='black', clip_on=False)\n",
    "g1.set_ylabel('')\n",
    "g1.set_yticklabels(g1.get_yticklabels(), rotation = 0, fontsize = 9)\n",
    "g1.set_xticklabels(g1.get_xticklabels(), rotation = 0, fontsize = 9)\n",
    "wrap_labels(g1, 10)\n",
    "ax1.set_title('Plot of MBONs > ' + responder + ' and their Δg across locomotor reactivity parameters')\n",
    "fig.tight_layout()\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_deltagheatmap_\" + secondrule +\".png\", dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff728022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta and delta g heatmap\n",
    "# \n",
    "dfreglist = [dfreg_bspeed.loc[dblist.index], dfreg_speed.loc[dblist.index], dfreg_fall.loc[dblist.index],dfreg_height.loc[dblist.index], dfreg_meanbout.loc[dblist.index], dfreg_bout.loc[dblist.index],dfreg_boutpos.loc[dblist.index], dfreg_maxvelocity.loc[dblist.index],dfreg_straightindex.loc[dblist.index], dfreg_displacementbetweenpause.loc[dblist.index]]\n",
    "totalregdf = pd.DataFrame()\n",
    "\n",
    "for n,k in zip(df55.columns[:-1], dfreglist):\n",
    "    k.columns = pd.MultiIndex.from_product([[n], k.columns.tolist()])\n",
    "    totalregdf = pd.concat([totalregdf, k], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d79f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = totalregdf.copy()\n",
    "fig, ax2 = plt.subplots(figsize=(18, 6))                \n",
    "\n",
    "first_row_headers = df0.columns.get_level_values(0)\n",
    "unique_first_row_headers = first_row_headers.unique()\n",
    "firstlabels = [ ' \\n '.join(wrap(l, 12)) for l in unique_first_row_headers]\n",
    "\n",
    "second_row_headers = df0.columns.get_level_values(1)\n",
    "second_headers = [l.replace('delta_', 'Δ') for l in second_row_headers.tolist()]\n",
    "\n",
    "y3 = sns.heatmap(df0, annot=True, fmt=\".1f\", vmin = -1.5, vmax = 1.5, cmap='YlGnBu',clip_on=False) # linewidths=0.5, linecolor='black', \n",
    "y3.set_ylabel('')\n",
    "# Calculate the positions for the primary x-tick labels (center of each cell)\n",
    "tick_positions = [i + 0.5 for i in range(len(second_headers))]\n",
    "\n",
    "# Set the primary x-axis labels (second row headers)\n",
    "ax2.set_xticks(tick_positions)\n",
    "ax2.set_xticklabels(second_headers, rotation=0)\n",
    "\n",
    "#Add the unique first row headers as additional labels\n",
    "for label in unique_first_row_headers:\n",
    "    # Find the positions for this label\n",
    "    positions = [i for i, x in enumerate(first_row_headers) if x == label]\n",
    "\n",
    "    # Calculate the center position of these columns\n",
    "    center_position = positions[0]\n",
    "    newlabel = textwrap.fill(label, 12)\n",
    "    \n",
    "    # Place the label with adjusted vertical position\n",
    "    ax2.text(center_position+0.5, len(second_headers)+0.5, newlabel, ha='left', va='top', rotation=0, weight='bold')\n",
    "    #wrap_labels(ax2, 10)\n",
    "    \n",
    "# Remove x-ax2is label\n",
    "ax2.set_xlabel(\"\")\n",
    "\n",
    "ax2.set_title('Plot of MBONs > ' + responder + ' and their Δg across locomotor reactivity parameters')\n",
    "ax2.vlines(list(range(3,3*12,3)), *ax2.get_xlim(), linewidth=3, color='k')\n",
    "\n",
    "\n",
    "#fig.tight_layout()\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_cohens d and delta gheatmap_\" + secondrule +\".png\", dpi = 1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f988214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstofmbonsiwant = ['VT999036', 'SS81521', 'SS81353', 'SS75199', 'SS77450', 'MB018B', 'SS01127','SS01337']\n",
    "totaldf_specificmbon = pd.DataFrame()\n",
    "ttregdf = totalregdf.reset_index(drop=False)\n",
    "for n in lstofmbonsiwant:\n",
    "    totaldf_specificmbon = pd.concat([totaldf_specificmbon, ttregdf[ttregdf['MBON'] == n]])\n",
    "    \n",
    "totaldf_specificmbon = totaldf_specificmbon.reset_index(drop=True)\n",
    "\n",
    "#adding extra axes label\n",
    "lobloclst = []\n",
    "mbonloclst = []\n",
    "for n in totaldf_specificmbon['MBON']:\n",
    "    df700 = totaldf_specificmbon.copy()\n",
    "    lobloclst.append(lobelocation[lobelocation['MBON'] == n]['Lobe_location'].values[0])\n",
    "    mbonloclst.append(lobelocation[lobelocation['MBON'] == n]['MBON number'].values[0])\n",
    "df700['Lobe'] = lobloclst\n",
    "df700['Name'] = mbonloclst\n",
    "\n",
    "\n",
    "df50 = df700.set_index(['Name'])\n",
    "df0 = df50.drop(['MBON', 'Lobe'], axis =1)\n",
    "\n",
    "#df0 = totaldf_specificmbon.set_index('MBON')\n",
    "fig, ax2 = plt.subplots(figsize=(18, 3))                \n",
    "\n",
    "first_row_headers = df0.columns.get_level_values(0)\n",
    "unique_first_row_headers = first_row_headers.unique()\n",
    "firstlabels = [ ' \\n '.join(wrap(l, 12)) for l in unique_first_row_headers]\n",
    "\n",
    "second_row_headers = df0.columns.get_level_values(1)\n",
    "second_headers = [l.replace('delta_', 'Δ') for l in second_row_headers.tolist()]\n",
    "\n",
    "y3 = sns.heatmap(df0, annot=True, fmt=\".1f\", vmin = -1.5, vmax = 1.5, cmap='YlGnBu',clip_on=False) # linewidths=0.5, linecolor='black', \n",
    "y3.set_ylabel('')\n",
    "# Calculate the positions for the primary x-tick labels (center of each cell)\n",
    "tick_positions = [i + 0.5 for i in range(len(second_headers))]\n",
    "\n",
    "# Set the primary x-axis labels (second row headers)\n",
    "ax2.set_xticks(tick_positions)\n",
    "ax2.set_xticklabels(second_headers, rotation=0)\n",
    "\n",
    "#Add the unique first row headers as additional labels\n",
    "for label in unique_first_row_headers:\n",
    "    # Find the positions for this label\n",
    "    positions = [i for i, x in enumerate(first_row_headers) if x == label]\n",
    "\n",
    "    # Calculate the center position of these columns\n",
    "    center_position = positions[0]\n",
    "    \n",
    "    newlabel = textwrap.fill(label, 12)\n",
    "    \n",
    "    # Place the label with adjusted vertical position\n",
    "    ax2.text(center_position+0.5, len(second_headers)-17.5, newlabel, ha='left', va='top', rotation=0, weight='bold')\n",
    "    #wrap_labels(ax2, 10)\n",
    "\n",
    "#secondary axes\n",
    "j8 = ax2.twinx()\n",
    "j8.set_ylim([0,ax2.get_ylim()[0]])\n",
    "j8.set_yticks(ax2.get_yticks())\n",
    "\n",
    "j8.set_yticklabels(df700['Lobe'].iloc[::-1], fontsize=10)\n",
    "j8.spines['top'].set_visible(False)\n",
    "j8.spines['right'].set_visible(False)\n",
    "j8.spines['bottom'].set_visible(False)\n",
    "j8.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "# Remove x-ax2is label\n",
    "ax2.set_xlabel(\"\")\n",
    "\n",
    "ax2.set_title('Plot of MBONs > ' + responder + ' and their Δg across locomotor reactivity parameters')\n",
    "ax2.vlines(list(range(3,3*12,3)), *ax2.get_xlim(), linewidth=3, color='k')\n",
    "\n",
    "\n",
    "#fig.tight_layout()\n",
    "\n",
    "#plt.savefig(openPath + \"images\\\\\" + date + \"_\" + responder + \"_cohens d and delta gheatmap_\" + secondrule +\".png\", dpi = 1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed285545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
